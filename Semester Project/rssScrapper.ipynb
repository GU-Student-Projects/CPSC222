{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Yh8AGgKuezCZ"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EJZxOL1lhzky"
      },
      "outputs": [],
      "source": [
        "def save_function(article_list):\n",
        "    with open('articles.txt', 'w') as outfile:\n",
        "        json.dump(article_list, outfile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9f7zTWz8ezCZ"
      },
      "outputs": [],
      "source": [
        "def hackernews_rss(hacker_news, article_list):\n",
        "    try:\n",
        "        r = requests.get(hacker_news)\n",
        "        soup = BeautifulSoup(r.content, features='xml')\n",
        "        articles = soup.findAll('item')\n",
        "        for a in articles:\n",
        "            title = a.find('title').text\n",
        "            link = a.find('link').text\n",
        "            published = a.find('pubDate').text\n",
        "            article = {\n",
        "                'title': title,\n",
        "                'link': link,\n",
        "                'published': published\n",
        "                }\n",
        "            article_list.append(article)\n",
        "        return article_list\n",
        "    except Exception as e:\n",
        "        print('The scraping job failed. See exception: ')\n",
        "        print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def contentScrapping(web_url):\n",
        "    try:\n",
        "        r = requests.get(web_url)\n",
        "        soup = BeautifulSoup(r.content, 'html.parser')\n",
        "        text = soup.find_all(text=True)\n",
        "\n",
        "        output = ''\n",
        "        blacklist = [\n",
        "            '[document]',\n",
        "            'noscript',\n",
        "            'header',\n",
        "            'html',\n",
        "            'meta',\n",
        "            'head', \n",
        "            'input',\n",
        "            'script',\n",
        "            # there may be more elements you don't want, such as \"style\", etc.\n",
        "            ]\n",
        "\n",
        "        for t in text:\n",
        "            if t.parent.name not in blacklist:\n",
        "                output += '{} '.format(t)\n",
        "        return output\n",
        "    except Exception as e:\n",
        "        print('The scraping job failed. See exception: ')\n",
        "        print(e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from string import punctuation\n",
        "from heapq import nlargest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgU0L_8WezCZ",
        "outputId": "04765595-4bd3-4d5c-b33b-853f946ddd25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting scraping\n",
            "Finished scraping\n"
          ]
        }
      ],
      "source": [
        "empty_list = []\n",
        "article_list = []\n",
        "newsSources = ['https://news.ycombinator.com/rss',]\n",
        "hackerNews = 'https://news.ycombinator.com/rss'\n",
        "print('Starting scraping')\n",
        "article_list = hackernews_rss(hackerNews,empty_list)\n",
        "print('Finished scraping')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0-days exploited by commercial surveillance vendor in Egypt\n",
            "https://blog.google/threat-analysis-group/0-days-exploited-by-commercial-surveillance-vendor-in-egypt/\n",
            "Three NorCal Tribes Announce Nation’s First Indigenous Ocean Protection Area\n",
            "https://lostcoastoutpost.com/2023/sep/22/three-norcal-tribes-announce-first-us-indigenous-m/\n",
            "Show HN: Paisa – Open-Source Personal Finance Manager\n",
            "https://paisa.fyi/\n",
            "Show HN: Summary Cat, a YouTube Video Summary Generator\n",
            "https://www.summarycat.com\n",
            "Show HN: Rapidpages – OSS alternative to vercel's v0\n",
            "https://github.com/rapidpages/rapidpages\n",
            "Run PostgreSQL. The Kubernetes Way\n",
            "https://cloudnative-pg.io/\n",
            "I made a transformer by hand (no training)\n",
            "https://vgel.me/posts/handmade-transformer/\n",
            "The Tragedy of Google Search\n",
            "https://www.theatlantic.com/technology/archive/2023/09/google-search-size-usefulness-decline/675409/\n",
            "Archaeologists find 500-year-old board game carved in ruins of Polish castle\n",
            "https://arstechnica.com/science/2023/09/archaeologists-find-500-year-old-board-game-carved-in-ruins-of-polish-castle/\n",
            "Turning an old car into a powerful generator\n",
            "https://blog.arduino.cc/2023/09/20/turning-an-old-car-into-a-powerful-generator/\n",
            "CFPB kicks off rulemaking to remove medical bills from credit reports\n",
            "https://www.consumerfinance.gov/about-us/newsroom/cfpb-kicks-off-rulemaking-to-remove-medical-bills-from-credit-reports/\n",
            "NASA JPL Open Source Rover That Runs ROS 2\n",
            "https://github.com/nasa-jpl/open-source-rover\n",
            "Signal: The Pqxdh Key Agreement Protocol\n",
            "https://signal.org/docs/specifications/pqxdh/\n",
            "GitHub Actions could be so much better\n",
            "https://blog.yossarian.net/2023/09/22/GitHub-Actions-could-be-so-much-better\n",
            "Not only Clojure – Chez Scheme: Lisp with native code speed\n",
            "https://yakihonne.com/article/naddr1qq2nw7n9va68s56dxf2x27z889v524z40f38wq3qu6qhg5ucu3xza4nlz94q90y720tr6l09avnq8y3yfp5qrv9v8susxpqqqp65wvyuq5c\n",
            "Show HN: Tome, aka Tom's Editor – a new command-line text editor\n",
            "https://github.com/boutell/tome/blob/main/README.md\n",
            "Show HN: Learn piano without sheet music\n",
            "https://jacobdoescode.com/piano-tabs\n",
            "The Design System Ecosystem\n",
            "https://bradfrost.com/blog/post/the-design-system-ecosystem/\n",
            "Polycentric interstate federalism among the Yoruba of Nigeria (2022) [pdf]\n",
            "https://cosmosandtaxis.files.wordpress.com/2022/09/kunleoyerinde_ct_vol10_iss11_12.pdf\n",
            "Principles for building and scaling feature flag systems\n",
            "https://docs.getunleash.io/topics/feature-flags/feature-flag-best-practices\n",
            "AWS Customers Cannot Escape IPv4\n",
            "https://tty.neveragain.de/2023/09/21/aws-cannot-escape-ipv4.html\n",
            "When half a million Americans died and nobody noticed (2012)\n",
            "https://theweek.com/us/46535/when-half-million-americans-died-and-nobody-noticed\n",
            "TOFU: Do You Check?\n",
            "https://cedwards.xyz/tofu-do-you-check/\n",
            "Hoxne Hoard\n",
            "https://en.wikipedia.org/wiki/Hoxne_Hoard\n",
            "iOS 17 Is a Prude\n",
            "https://old.reddit.com/r/iphone/comments/16nqk30/ios_17_is_a_prude/\n",
            "How to Roman Republic, Part IV: The Senate\n",
            "https://acoup.blog/2023/09/22/collections-how-to-roman-republic-part-iv-the-senate/\n",
            "Java 21: The Nice, the Meh, and the Momentous\n",
            "https://horstmann.com/unblog/2023-09-19/index.html\n",
            "Dumpster Tektronix 2465B Restoration\n",
            "https://sunestra.fr/posts/repair/scope/\n",
            "Quantum Poetics\n",
            "https://aeon.co/essays/borges-and-heisenberg-converged-on-the-slipperiness-of-language\n",
            "Ways to capture changes in Postgres\n",
            "https://blog.sequin.io/all-the-ways-to-capture-changes-in-postgres/\n"
          ]
        }
      ],
      "source": [
        "for article in article_list:\n",
        "    print(article['title'])\n",
        "    print(article['link'])\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "datascience",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
