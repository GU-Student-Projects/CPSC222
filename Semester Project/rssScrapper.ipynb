{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Yh8AGgKuezCZ"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_function(article_list):\n",
        "    with open('articles.txt', 'w') as outfile:\n",
        "        json.dump(article_list, outfile)"
      ],
      "metadata": {
        "id": "EJZxOL1lhzky"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "9f7zTWz8ezCZ"
      },
      "outputs": [],
      "source": [
        "def hackernews_rss(hackerNews):\n",
        "    article_list = []\n",
        "    try:\n",
        "        r = requests.get(hackerNews)\n",
        "        soup = BeautifulSoup(r.content, features='xml')\n",
        "        articles = soup.findAll('item')\n",
        "        for a in articles:\n",
        "            title = a.find('title').text\n",
        "            link = a.find('link').text\n",
        "            published = a.find('pubDate').text\n",
        "            article = {\n",
        "                'title': title,\n",
        "                'link': link,\n",
        "                'published': published\n",
        "                }\n",
        "            article_list.append(article)\n",
        "        return save_function(article_list)\n",
        "    except Exception as e:\n",
        "        print('The scraping job failed. See exception: ')\n",
        "        print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgU0L_8WezCZ",
        "outputId": "04765595-4bd3-4d5c-b33b-853f946ddd25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting scraping\n",
            "Finished scraping\n"
          ]
        }
      ],
      "source": [
        "hackerNews = 'https://news.ycombinator.com/rss'\n",
        "print('Starting scraping')\n",
        "hackernews_rss(hackerNews)\n",
        "print('Finished scraping')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "datascience",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}